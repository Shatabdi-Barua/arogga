{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4789e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.arogga.com/brand/33375/\n",
      "https://www.arogga.com/brand/33374/\n",
      "https://www.arogga.com/brand/33373/\n",
      "https://www.arogga.com/brand/33372/\n",
      "https://www.arogga.com/brand/33371/\n",
      "https://www.arogga.com/brand/33370/\n",
      "https://www.arogga.com/brand/33369/\n",
      "https://www.arogga.com/brand/33368/\n",
      "https://www.arogga.com/brand/33367/\n",
      "https://www.arogga.com/brand/33366/\n",
      "https://www.arogga.com/brand/33365/\n",
      "https://www.arogga.com/brand/33364/\n",
      "https://www.arogga.com/brand/33363/\n",
      "https://www.arogga.com/brand/33362/\n",
      "https://www.arogga.com/brand/33361/\n",
      "https://www.arogga.com/brand/33360/\n",
      "https://www.arogga.com/brand/33359/\n",
      "https://www.arogga.com/brand/33358/\n",
      "https://www.arogga.com/brand/33357/\n",
      "https://www.arogga.com/brand/33356/\n",
      "https://www.arogga.com/brand/33355/\n",
      "https://www.arogga.com/brand/33354/\n",
      "https://www.arogga.com/brand/33353/\n",
      "https://www.arogga.com/brand/33352/\n",
      "https://www.arogga.com/brand/33351/\n",
      "https://www.arogga.com/brand/33350/\n",
      "https://www.arogga.com/brand/33349/\n",
      "https://www.arogga.com/brand/33348/\n",
      "https://www.arogga.com/brand/33347/\n",
      "https://www.arogga.com/brand/33346/\n",
      "https://www.arogga.com/brand/33345/\n",
      "https://www.arogga.com/brand/33344/\n",
      "https://www.arogga.com/brand/33343/\n",
      "https://www.arogga.com/brand/33342/\n",
      "https://www.arogga.com/brand/33341/\n",
      "https://www.arogga.com/brand/33340/\n",
      "https://www.arogga.com/brand/33339/\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "# import pandas as pd\n",
    "import openpyxl\n",
    "# import mysql.connector\n",
    "import json\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
    "from sqlalchemy import insert\n",
    "import pymysql\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG, filename='/home/trenza/Documents/arogga/logt.log', filemode='w',format=\"{asctime} {levelname:<8} {message}\", style='{',)\n",
    "# logger = logging.getLogger('ftpuploader')\n",
    "# hdlr = logging.FileHandler('/home/trenza/Documents/arogga/logt.log')\n",
    "# formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "# hdlr.setFormatter(formatter)\n",
    "# logger.addHandler(hdlr)\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "pymysql.install_as_MySQLdb()\n",
    "engine = create_engine('mysql://root:@localhost/scrape_data')\n",
    "conn = engine.connect()\n",
    "# metadata = db.MetaData()\n",
    "meta = MetaData()\n",
    "products = db.Table('arogga', meta, autoload=True, autoload_with=engine)\n",
    "db_sku = []\n",
    "########################################## for count ##############################\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "cnt = session.query(products).count()\n",
    "# print(\"Count:\", result)\n",
    "if cnt == 0:\n",
    "    n = 37000\n",
    "else:\n",
    "    s = products.select().limit(1)\n",
    "    myresult = conn.execute(s)\n",
    "    for x in myresult:\n",
    "        db_sku.append(x[0])\n",
    "        n = x[0]\n",
    "        n = n-1\n",
    "# print(\"n=\", n)\n",
    "sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver', options=options)\n",
    "driver.set_window_size(1920, 1080)\n",
    "# n = 36629\n",
    "m = n-100\n",
    "# print('m= ', m)\n",
    "# url = [];\n",
    "url_prefix = \"https://www.arogga.com/brand/\"\n",
    "while n > m:\n",
    "    time.sleep(3)\n",
    "    # print('n=', n)\n",
    "#     start_time = time.time()\n",
    "#     url.append(url_prefix+str(n)+\"/\")\n",
    "    url = url_prefix+str(n)+\"/\"\n",
    "#     print(n)\n",
    "    datas = []\n",
    "    disc = []\n",
    "    error = []\n",
    "    u = url\n",
    "#     for u in url:\n",
    "    print(u)\n",
    "    try:\n",
    "        status = requests.get(u)\n",
    "        st_code = status.status_code\n",
    "#         print(st_code)\n",
    "        if st_code == 200:\n",
    "            all_data = dict()\n",
    "            all_data['product_images'] = ''\n",
    "            all_data['main_img'] = ''\n",
    "            all_data['medicine_name'] = ''\n",
    "            all_data['med_gram'] = ''\n",
    "            all_data['mtype'] = ''\n",
    "            all_data['mcompany'] = ''\n",
    "            all_data['people_view'] = ''\n",
    "            all_data['generic'] = ''\n",
    "            all_data['best_price_amount'] = ''\n",
    "            all_data['previous_price_amount'] = ''\n",
    "            all_data['cart'] = ''\n",
    "            all_data['cart_list'] = ''\n",
    "            all_data['offer_title'] = ''\n",
    "            all_data['additional_offers'] = ''\n",
    "            all_data['other_desciption'] = ''\n",
    "            all_data['alternative_brands'] = ''\n",
    "            all_data['product_references'] = ''\n",
    "            all_data['disclaimer'] = ''\n",
    "            driver.get(u)\n",
    "            r = driver.page_source\n",
    "            soup = BeautifulSoup(r, \"html.parser\")\n",
    "            all_data['url'] = u\n",
    "#                 print(all_data['url'])\n",
    "#                 break;\n",
    "            data_sku = json.loads(soup.find('script', type=\"application/ld+json\").text)\n",
    "            all_data['sku'] = data_sku['sku']\n",
    "#             print(all_data['sku'])\n",
    "            sku = data_sku['sku']\n",
    "            sk = int(sku)\n",
    "            data_cat_id = json.loads(soup.find('script', id=\"__NEXT_DATA__\").text)\n",
    "            all_data['cat_id'] = data_cat_id[\"props\"][\"pageProps\"][\"product\"][\"data\"][\"medicine\"][\"cat_id\"]\n",
    "            img_arr = []\n",
    "        #       ########################## selector image #######################\n",
    "            sdiv_img = soup.find('div', {'class': 'selectors'})\n",
    "            for simg in sdiv_img.find_all('a'):\n",
    "                img_arr.append(simg.get('href'))\n",
    "            all_data['product_images'] = img_arr\n",
    "            \n",
    "        #        ########################## main image ###########################\n",
    "            main_img = soup.find('div', {'class': 'updateClass'})\n",
    "            all_data['main_img'] = main_img.a['href']\n",
    "\n",
    "        #             ########################## med name ###########################\n",
    "            for med_name in soup.find_all('h1', {'class': 'MuiTypography-root jss2 MuiTypography-h1'}):\n",
    "                for mgram in med_name.find_all('span', {'class': 'jss3'}):\n",
    "                    all_data['med_gram'] = mgram.text\n",
    "                med_name.find('span').extract()\n",
    "                all_data['medicine_name'] = med_name.text\n",
    "            \n",
    "        #       ############# med type and company ###########################\n",
    "            med = soup.find_all('div', {'class': 'MuiGrid-root jss23 MuiGrid-item MuiGrid-grid-lg-6'})\n",
    "            \n",
    "            count = 0\n",
    "            y = []\n",
    "            for med in soup.find_all('h6'):\n",
    "                x = med.text\n",
    "                y.append(x)\n",
    "                if len(y) <= 1:                   \n",
    "                    all_data['mtype'] = ''\n",
    "                    all_data['mcompany'] = ''\n",
    "                else:\n",
    "                    all_data['mtype'] = y[0]\n",
    "                    all_data['mcompany'] = y[1]\n",
    "            # all_data['mtype'] = y[0]\n",
    "            # all_data['mcompany'] = y[1]\n",
    "\n",
    "        #       ########################### Generic Name #############################\n",
    "            for span_search in soup.find_all('div', {'class': 'MuiGrid-root jss23 MuiGrid-item MuiGrid-grid-lg-6'}):\n",
    "                span_text_jss23 = []\n",
    "                for z in span_search.find_all('div'):\n",
    "                    span_text = z.text\n",
    "                    span_text_jss23.append(span_text)\n",
    "                for d in span_search.find_all('div', {'class': 'jss6'}):\n",
    "                    for dd in d.find_all('div', {'class': 'jss7'}):\n",
    "                        for pv in dd.find_all('span'):\n",
    "                            all_data['people_view'] = pv.text\n",
    "            all_data['generic'] = span_text_jss23[1]\n",
    "            \n",
    "        #       ########################## med price ###########################\n",
    "            med_price = soup.find_all('div', {'class': 'jss8'})\n",
    "            price = []\n",
    "            for med_price in soup.find_all('div', {'class': 'jss8'}):\n",
    "                link = med_price.find_all('div')\n",
    "                for l in link:\n",
    "                    price.append(l.text)\n",
    "\n",
    "            if len(price) > 2:\n",
    "                all_data['best_price_title'] = price[0]\n",
    "                all_data['best_price_amount'] = price[1]\n",
    "                all_data['previous_price_title'] = price[2]\n",
    "                all_data['previous_price_amount'] = price[3]\n",
    "            else:\n",
    "                all_data['best_price_title'] = price[0]\n",
    "                all_data['best_price_amount'] = price[1]\n",
    "                all_data['previous_price_title'] = 0\n",
    "                all_data['previous_price_amount'] = 0\n",
    "            \n",
    "        #             ########################## cart ###########################\n",
    "            all_data['cart'] = soup.find('span', {'class': 'MuiButton-label'}).text\n",
    "#             print(all_data['sku'])\n",
    "            elem = soup.find('span', {'id':'btn'})\n",
    "#             print(elem)\n",
    "            cart_array = []\n",
    "            if elem == None:\n",
    "                all_data['cart_list'] = ''\n",
    "            else:\n",
    "                element = driver.find_element(By.CSS_SELECTOR, 'span[id|=\"btn\"]')\n",
    "#                 print(type(element))\n",
    "                element.click()\n",
    "#                 cart_list = driver.find_elements(By.XPATH, '//div[@class=\"MuiPaper-root MuiMenu-paper MuiPopover-paper MuiPaper-elevation8 MuiPaper-rounded\"]')\n",
    "    #             print(cart_list[0].text)\n",
    "#                 all_data['cart_list'] = cart_list[0].text\n",
    "#             print(all_data['cart_list'])\n",
    "                cart_list = driver.find_elements(By.XPATH, '//li[@class=\"MuiButtonBase-root MuiListItem-root MuiMenuItem-root add-to-cart  add-to-cart-undefined MuiMenuItem-gutters MuiListItem-gutters MuiListItem-button\"]')\n",
    "#             print(cart_list)\n",
    "                i = 0\n",
    "                try:\n",
    "                    for cart_l in cart_list:\n",
    "#                     cart_list.append(cart_l.text)\n",
    "#                     print(cart_l.text)\n",
    "                        cart_list = cart_l.text\n",
    "#                     print(cart_list)\n",
    "                        cart_array.append(cart_list )\n",
    "                        i += 1\n",
    "                except Exception as e: print(e)\n",
    "                all_data['cart_list'] = cart_array\n",
    "        #             ########################## offers ###########################\n",
    "            offers = dict()\n",
    "            offer_title = soup.find('h2', {'class': 'jss11'}).text\n",
    "            all_data['offer_title'] = offer_title\n",
    "            offer_details = []\n",
    "            for all_offers in soup.find_all('div', {'class': 'jss14 jss22'}):\n",
    "                offer_details.append(all_offers.text)\n",
    "            all_data['additional_offers'] = offer_details\n",
    "\n",
    "        #       ########################## other description ###########################\n",
    "            for other in soup.find_all('div', {'class': 'jss90'}):\n",
    "                other_desc = other.find_all('div', {'class': 'jss69'})\n",
    "            for ot in other_desc:\n",
    "                all_data['other_desciption'] = ot\n",
    "#                     print(all_data['other_desciption'])\n",
    "#                         for ot_li in ot.find_all('li'):\n",
    "#                             other_Des = str(ot_li)\n",
    "#                             other_Des = other_Des.encode(\"utf-8\")\n",
    "# #                             print(other_Des)\n",
    "#                             other = other_Des.replace(\"/\",\" \")\n",
    "#                             other_Des = preg_replace('/[0-9\\@\\.\\;\\\" \"]+/', '', other_Des)\n",
    "#                         print(other)\n",
    "\n",
    "        #             ########################## disclaimer ###########################\n",
    "            disc.append(soup.find('div', {'class': 'jss89'}).p.text)\n",
    "            all_data['disclaimer'] = disc[0]\n",
    "        #             ########################## alternative products ###########################\n",
    "            product_references = []\n",
    "            for alt in soup.find_all('div', {'class': 'jss69'}):\n",
    "                for brn in alt.find_all('div', {'class': 'jss93'}):\n",
    "                    all_data['alternative_brands'] = brn\n",
    "    #                     print(all_data['alternative_brands'])\n",
    "                    for nav_elem in brn.find_all('div', {'class': 'MuiButtonBase-root MuiListItem-root jss133 MuiListItem-gutters MuiListItem-button'}):\n",
    "                        for pro_ref in nav_elem.find_all('a'):\n",
    "                            product_references.append(pro_ref.get('href'))\n",
    "            all_data['product_references'] = product_references\n",
    "           \n",
    "            datas.append(all_data)\n",
    "    #             print(all_data['alternative_brands'])\n",
    "        #             ############################# db duplicate check, insert #################################\n",
    "           \n",
    "#             print(all_data)\n",
    "            if all_data['sku'] not in db_sku:\n",
    "#                 print(all_data['alternative_brands'])\n",
    "                all_data['product_images'] = str(all_data['product_images'])\n",
    "                all_data['main_img'] = str(all_data['main_img'])\n",
    "                offer_details = str(offer_details)\n",
    "                all_data['other_desciption'] = str(all_data['other_desciption'])\n",
    "#                     print(all_data['other_desciption'])\n",
    "                all_data['alternative_brands'] = str(all_data['alternative_brands'])\n",
    "#                     print(all_data['alternative_brands'])\n",
    "                all_data['product_references'] = str(all_data['product_references'])\n",
    "                all_data['disclaimer'] = str(all_data['disclaimer'])\n",
    "#                 print(all_data['sku'])\n",
    "#                     print(type(offer_details))\n",
    "#                 print(str(all_data['cart']))\n",
    "#                     print(str(all_data['medicine_name']),str(all_data['med_gram']),str(all_data['mtype']),\n",
    "#                          str(all_data['mcompany']),str(all_data['people_view']), str(all_data['generic']),str(all_data['best_price_amount']),)\n",
    "#                     ins = products.insert().values(sku = all_data['sku'],other_desciption=str(all_data['other_desciption']))\n",
    "#                     ins = products.insert().values(sku = all_data['sku'], url = all_data['url'],\n",
    "#                                                    product_images=all_data['product_images'],\n",
    "#                                                    main_img=all_data['main_img'],\n",
    "#                                                    medicine_name=str(all_data['medicine_name']),\n",
    "#                                                    medicine_weight=str(all_data['med_gram']),\n",
    "#                                                    medicine_type=str(all_data['mtype']),\n",
    "#                                                    medicine_company=str(all_data['mcompany']),\n",
    "#                                                    people_view=str(all_data['people_view']),\n",
    "#                                                    generic=str(all_data['generic']),\n",
    "#                                                    best_price_amount=str(all_data['best_price_amount']),\n",
    "#                                                    previous_price_amount=str(all_data['previous_price_amount']),\n",
    "#                                                    cart=str(all_data['cart']),\n",
    "#                                                    offer_title=str(all_data['offer_title']),\n",
    "#                                                    additional_offers=str(offer_details),\n",
    "#                                                    other_desciption=str(all_data['other_desciption'],\n",
    "#                                                    alternative_brands=all_data['alternative_brands'],\n",
    "#                                                    product_references=all_data['product_references'],\n",
    "#                                                    disclaimer=all_data['disclaimer'],\n",
    "#                                                    cat_id=all_data['cat_id'],status=1)\n",
    "# #                                                   )\n",
    "                ins = products.insert().values(sku=all_data['sku'], url=all_data['url'],\n",
    "                                               product_images=all_data['product_images'], main_img=all_data['main_img'],\n",
    "                                               medicine_name=str(all_data['medicine_name']), medicine_weight=str(all_data['med_gram']),\n",
    "                                               medicine_type=str(all_data['mtype']), medicine_company=str(all_data['mcompany']),\n",
    "                                               people_view=str(all_data['people_view']), generic=str(all_data['generic']),\n",
    "                                               best_price_amount=str(\n",
    "                                                   all_data['best_price_amount']),\n",
    "                                               previous_price_amount=str(\n",
    "                                                   all_data['previous_price_amount']),\n",
    "                                               cart=str(all_data['cart']), variation_list = str(all_data['cart_list']),\n",
    "                                               offer_title=str(all_data['offer_title']),\n",
    "                                               additional_offers=str(offer_details), other_desciption=str(all_data['other_desciption']),\n",
    "                                               alternative_brands=all_data['alternative_brands'],\n",
    "                                               product_references=all_data['product_references'],\n",
    "                                               disclaimer=all_data['disclaimer'], cat_id=all_data['cat_id'], status=1)\n",
    "# #                     print(ins)\n",
    "#                 # logging.debug('log1')\n",
    "                reslt = conn.execute(ins)\n",
    "                # logging.debug('debug')\n",
    "                # logging.info('info')\n",
    "                # print('log')\n",
    "#                 logging.info(str(n) + \" inserted successfully\")\n",
    "                db_sku.append(all_data['sku'])\n",
    "    #                 print(reslt)\n",
    "        elif st_code == 404:\n",
    "            ins = products.insert().values(sku=n, status=0)\n",
    "            reslt = conn.execute(ins)\n",
    "#             # logging.basicConfig(level=logging.DEBUG, filename='log_arr.log', filemode='w',\n",
    "#             #                     format=\"{asctime} {levelname:<8} {message}\", style='{',)\n",
    "#             logging.warning(str(n) + \" status 404 inserted\")\n",
    "            db_sku.append(n)\n",
    "#             break\n",
    "    #         end_time = time.time()\n",
    "#             elif st_code == 308:\n",
    "#                 ins = products.insert().values(sku=n, status = 0)\n",
    "#                 reslt = conn.execute(ins)\n",
    "#                 db_sku.append(n)\n",
    "#                 break\n",
    "        else:\n",
    "            error.append(n)\n",
    "            break\n",
    "    except:\n",
    "        #         print(1)\n",
    "        ins = products.insert().values(sku=n, status=0)\n",
    "        reslt = conn.execute(ins)\n",
    "#         # logging.basicConfig(filename='log_arr.log', filemode='w',\n",
    "#         #                     format='%(name)s - %(levelname)s - %(message)s')\n",
    "#         logging.error(sys.exc_info()[0])\n",
    "#         logging.info(str(n) + \" error\")\n",
    "        db_sku.append(n)\n",
    "#         continue\n",
    "    n = n-1   \n",
    "# print(all_data)\n",
    "driver.close()\n",
    "driver.quit()\n",
    "\n",
    "#     time_diff = end_time - start_time\n",
    "#     print(time_diff)\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb22e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.36-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m215.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 KB\u001b[0m \u001b[31m636.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m649.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-1.1.2 sqlalchemy-1.4.36\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/media/trenza/6C50D42C50D3FAB2/Shatabdi/arogga_data/arogga_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e654cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m639.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.5.18.1-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.2/155.2 KB\u001b[0m \u001b[31m993.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 KB\u001b[0m \u001b[31m969.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2022.5.18.1 charset-normalizer-2.0.12 idna-3.3 requests-2.27.1 urllib3-1.26.9\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/media/trenza/6C50D42C50D3FAB2/Shatabdi/arogga_data/arogga_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed764a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.1.5-py3-none-any.whl (979 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.4/979.4 KB\u001b[0m \u001b[31m563.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m558.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[secure,socks]~=1.26 in ./arogga_env/lib/python3.8/site-packages (from selenium) (1.26.9)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.0/359.0 KB\u001b[0m \u001b[31m634.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m603.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna in ./arogga_env/lib/python3.8/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./arogga_env/lib/python3.8/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi in ./arogga_env/lib/python3.8/site-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.5.18.1)\n",
      "Collecting cryptography>=1.3.4\n",
      "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m225.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m572.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m585.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in ./arogga_env/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 KB\u001b[0m \u001b[31m654.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in ./arogga_env/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
      "Installing collected packages: sortedcontainers, sniffio, PySocks, outcome, h11, async-generator, wsproto, trio, cryptography, trio-websocket, pyOpenSSL, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.5 sniffio-1.2.0 sortedcontainers-2.4.0 trio-0.20.0 trio-websocket-0.9.2 wsproto-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/media/trenza/6C50D42C50D3FAB2/Shatabdi/arogga_data/arogga_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
